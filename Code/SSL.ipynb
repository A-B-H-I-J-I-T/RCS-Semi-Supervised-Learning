{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's Begin\n",
      "        id entity sentiment                                              tweet\n",
      "0     6001   FIFA  Positive  The fact that Andy Gray hates this so much mak...\n",
      "1     6001   FIFA  Positive  The fact that Andy Gray hates it so much makes...\n",
      "2     6001   FIFA  Positive  The fact that Andy Gray hates it so much makes...\n",
      "3     6001   FIFA  Positive  The fact that Andy himself hates this so much ...\n",
      "4     6001   FIFA  Positive  The fact that Andy Gray probably hates this so...\n",
      "...    ...    ...       ...                                                ...\n",
      "2329  6399   FIFA  Negative  I think if we weren't in a stalemate, I would ...\n",
      "2330  6399   FIFA  Negative  I think if we didn't have a lockout, I would s...\n",
      "2331  6399   FIFA  Negative  I think if we weren't in lockdown, people have...\n",
      "2332  6399   FIFA  Negative  I really think if ever we weren't in lockdown,...\n",
      "2333  6399   FIFA  Negative  I think if we weren't on lockdown, I'd have st...\n",
      "\n",
      "[1680 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random \n",
    "print(\"Let's Begin\")\n",
    "\n",
    "df_fifa = pd.read_csv(\"../Data/Fifa Twitter.csv\")\n",
    "\n",
    "df_fifa = df_fifa[(df_fifa['sentiment'] == \"Positive\" )|( df_fifa['sentiment']  == \"Negative\")]\n",
    "print(df_fifa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "entity        0\n",
      "sentiment     0\n",
      "tweet        16\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "entity       0\n",
       "sentiment    0\n",
       "tweet        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop NA's\n",
    "print(df_fifa.isna().sum())\n",
    "df_fifa = df_fifa.dropna()\n",
    "df_fifa.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    1169\n",
       "Positive     495\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fifa[\"sentiment\"].describe()\n",
    "#df_fifa[df_fifa[\"sentiment\"] == \"positive\"].length\n",
    "df_fifa.groupby('sentiment')['sentiment'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the raw text\n",
    "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
    "\n",
    " Tokenizing the string \n",
    " Lowercasing\n",
    " Removing stop words and punctuation\n",
    " Stemming\n",
    "\n",
    "The videos explained each of these steps and why they are important. Let's see how we can do these to a given tweet. We will choose just one and see how this is transformed by each preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhij\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download the stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflowers favourites happy Friday off… \n"
     ]
    }
   ],
   "source": [
    "# tweet = \"My beautiful sunflowers on a sunny Friday morning off :) \\\n",
    "#     #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\"\n",
    "# print('\\033[92m' + tweet)\n",
    "# print('\\033[94m')\n",
    "\n",
    "def tweet_cleaning(tweet):\n",
    "# remove old style retweet text \"RT\"\n",
    "    tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "# remove hyperlinks\n",
    "    tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "\n",
    "# remove hashtags\n",
    "# only removing the hash # sign from the word\n",
    "    tweet2 = re.sub(r'#', '', tweet2)\n",
    "    return tweet2\n",
    "print(tweet_cleaning(\"sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "198dc38c81252feb4faa0d475279f5f6c993dd4570bd3709069413259282040c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
