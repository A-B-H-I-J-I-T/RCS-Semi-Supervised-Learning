{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['im', 'get', 'borderland', 'murder']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['come', 'border', 'kill']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['im', 'get', 'borderland', 'kill']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['im', 'come', 'borderland', 'murder']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['im', 'get', 'borderland', '2', 'murder']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['im', 'get', 'borderland', 'murder']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['spent', 'hour', 'make', 'someth', 'fun', '. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['spent', 'coupl', 'hour', 'someth', 'fun', 'k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['spent', 'hour', 'someth', 'fun', 'know', \"i'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['spent', 'hour', 'make', 'someth', 'fun', '. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0              ['im', 'get', 'borderland', 'murder']      1\n",
       "1                         ['come', 'border', 'kill']      1\n",
       "2                ['im', 'get', 'borderland', 'kill']      1\n",
       "3             ['im', 'come', 'borderland', 'murder']      1\n",
       "4         ['im', 'get', 'borderland', '2', 'murder']      1\n",
       "5              ['im', 'get', 'borderland', 'murder']      1\n",
       "6  ['spent', 'hour', 'make', 'someth', 'fun', '. ...      1\n",
       "7  ['spent', 'coupl', 'hour', 'someth', 'fun', 'k...      1\n",
       "8  ['spent', 'hour', 'someth', 'fun', 'know', \"i'...      1\n",
       "9  ['spent', 'hour', 'make', 'someth', 'fun', '. ...      1"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(\"../Data/cleaned_tweets.csv\")\n",
    "df_tweets = df_tweets[[\"tweet\",\"sentiment\"]]\n",
    "\n",
    "# define a function to add label\n",
    "def row_label(row):\n",
    "    return 1 if row[\"sentiment\"]==\"Positive\" else 0\n",
    "\n",
    "# def remove_brakets(row):\n",
    "#     return row[\"tweet\"].replace(']','').replace\n",
    "def remove_brakets(row):\n",
    "    string= re.sub('\\[|\\]|\\'|\\.|\"|,', '', row[\"tweet\"])\n",
    "    #string = string.replace(\",\",\"\")\n",
    "    return string\n",
    "\n",
    "df_tweets[\"label\"] = df_tweets.apply(row_label, axis=1)\n",
    "# df_tweets[\"tweet\"] = df_tweets.apply(remove_brakets, axis=1)\n",
    "df_tweets.drop(\"sentiment\",axis=1, inplace=True)\n",
    "\n",
    "df_tweets.drop_duplicates()\n",
    "#reduce the data\n",
    "df_tweets_inp = df_tweets.sample(frac=0.9, random_state=42)\n",
    "df_test = df_tweets.drop(df_tweets_inp.index)\n",
    "#df_test = df_test.sample(frac=0.1, random_state=42)\n",
    "\n",
    "#seperate labelled and unlabelled data\n",
    "df_labeled_data = df_tweets_inp.sample(frac=0.25, random_state=42)\n",
    "df_unlabeled_data = df_tweets_inp.drop(df_labeled_data.index)\n",
    "#df_unlabeled_data.drop(\"label\",axis=1, inplace=True)\n",
    "#print(df_test[df_test[\"label\"]==1].count,df_test[df_test[\"label\"]==0].count)\n",
    "#print(df_labeled_data[df_labeled_data[\"label\"]==1].count,df_labeled_data[df_labeled_data[\"label\"]==0].count)\n",
    "\n",
    "\n",
    "\n",
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text data into numerical feature vectors using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "labeled_features = vectorizer.fit_transform(df_labeled_data['tweet'])\n",
    "test_features = vectorizer.transform(df_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Supervised: 0.8437572657521507\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression model on the labeled data\n",
    "# model = LogisticRegression()\n",
    "# model = MultinomialNB()\n",
    "\n",
    "# model = Sequential()\n",
    "# vocab_size = 25000\n",
    "# max_length = 21\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length))\n",
    "# model.add(LSTM(units=64))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(labeled_features, df_labeled_data['label'])\n",
    "\n",
    "# evaluate the performance of the model on the test data\n",
    "accuracy = model.score(test_features, df_test['label'])\n",
    "print(\"Accuracy Supervised:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1 0.8598000465008138\n",
      "Accuracy 2 0.8700302255289467\n",
      "Accuracy 3 0.8739827946989073\n",
      "Accuracy 4 0.8802604045570798\n",
      "Accuracy 5 0.8856079981399675\n"
     ]
    }
   ],
   "source": [
    "def splitData(dataframe,noofdivision):\n",
    "    # list = []\n",
    "    # totaldfsize = dataframe.shape[0]\n",
    "    # for i in range(1,noofdivision+1):\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    lst_dfs = np.array_split(dataframe,noofdivision)\n",
    "    return lst_dfs\n",
    "# totaldfsize = df_unlabeled_data.shape[0]\n",
    "# print(totaldfsize)\n",
    "# lst_dfs = splitData(df_unlabeled_data,5)\n",
    "# len(lst_dfs)\n",
    "\n",
    "def selftrain(model,df_lab_data,lst_dfs,ini_acc):\n",
    "    threshold_acc = ini_acc\n",
    "    i = 0\n",
    "    for df in lst_dfs:\n",
    "       i +=1\n",
    "       unlabeled_features = vectorizer.transform(df['tweet'])\n",
    "       probabilities = model.predict_proba(unlabeled_features)\n",
    "       confidence = np.max(probabilities, axis=1)\n",
    "       threshold = np.percentile(confidence, 0.1)\n",
    "       indices = np.where(confidence >= threshold)[0]\n",
    "       df_prev_lab = df_lab_data\n",
    "       df_lab_data = df_lab_data.append(df.iloc[indices])\n",
    "       labeled_features = vectorizer.transform(df_lab_data['tweet']) \n",
    "       model.fit(labeled_features, df_lab_data['label'])\n",
    "       acurcy = model.score(test_features, df_test['label'])\n",
    "       print(\"Accuracy\",i,acurcy)\n",
    "       if(acurcy < threshold_acc):\n",
    "           df_lab_data = df_prev_lab\n",
    "    return model\n",
    "\n",
    "lst_dfs = splitData(df_unlabeled_data,5)\n",
    "\n",
    "model = selftrain(model,df_labeled_data,lst_dfs,accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the sentiment of the unlabeled data\n",
    "# unlabeled_features = vectorizer.transform(df_unlabeled_data['tweet'])\n",
    "# predicted_sentiments = model.predict(unlabeled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the most confident predictions and add them to the labeled data\n",
    "# probabilities = model.predict_proba(unlabeled_features)\n",
    "# confidence = np.max(probabilities, axis=1)\n",
    "# threshold = np.percentile(confidence, 0.1)\n",
    "# indices = np.where(confidence >= threshold)[0]\n",
    "# df_labeled_data = df_labeled_data.append(df_unlabeled_data.iloc[indices])\n",
    "# labeled_features = vectorizer.transform(df_labeled_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrain the model on the updated labeled data\n",
    "# model.fit(labeled_features, df_labeled_data['label'])\n",
    "\n",
    "# # evaluate the performance of the model on the test data\n",
    "# accuracy = model.score(test_features, df_test['label'])\n",
    "# print(\"Accuracy: SemiSupervised\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
